{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18366432",
   "metadata": {},
   "source": [
    "<h1>Introduction to Text Analytics</h1>\n",
    "<h3>Group Assignment</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227da32a",
   "metadata": {},
   "source": [
    "Group 6\n",
    "\n",
    "* Akshay Ramdev - 12220032\n",
    "* Charanjeet Singh - 12220064\n",
    "* Pooja Nilesh Doshi - 12220028\n",
    "* Snigdha Debashis Bhattacharjee - 12220067\n",
    "* Vinayak Dave - 12220047"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec436aff",
   "metadata": {},
   "source": [
    "## Q1 (Question 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dee6b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              reviewText  overall\n",
      "0      They look good and stick good! I just don't li...      4.0\n",
      "1      These stickers work like the review says they ...      5.0\n",
      "2      These are awesome and make my phone look so st...      5.0\n",
      "3      Item arrived in great time and was in perfect ...      4.0\n",
      "4      awesome! stays on, and looks great. can be use...      5.0\n",
      "...                                                  ...      ...\n",
      "49995  I was sceptical about these batteries because ...      5.0\n",
      "49996  These batteries have been great replacements i...      5.0\n",
      "49997  It works. The thunderbolt eats battery life li...      4.0\n",
      "49998  These batteries have held up for over a year n...      4.0\n",
      "49999  I've had my HTC Thunderbolt for almost 2 years...      5.0\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'C:/Users/SNIGGDHA/dataset.txt'  # Path to the dataset file\n",
    "\n",
    "# Read the dataset file in JSON format and extract review text and overall rating\n",
    "# Create a list to store the extracted reviews\n",
    "reviews = []\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        review = {\n",
    "            \"reviewText\": data['reviewText'],\n",
    "            \"overall\": data['overall']\n",
    "        }\n",
    "        reviews.append(review)\n",
    "\n",
    "df = pd.DataFrame(reviews)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d79100",
   "metadata": {},
   "source": [
    "#### import json: This line imports the json module to work with JSON data in Python.\n",
    "#### import pandas: This line imports the pandas library which provides data structures and data analysis tools to work with tabular data.\n",
    "#### The above piece of code reads the dataset.txt file line by line using iterated for loop and treats each line as json object.\n",
    "#### with open(file_path, 'r') as file:- This line opens the file mentioned in the filepath in the read mode. The with funcrtion ensures closure of file after the process.\n",
    "#### data = json.loads(line) :- This line converts the JSON string into a Python dict object.\n",
    "#### review:- This dict is created to fetch value associated with reviewText and overall key.Later dict object review is converted into a Dataframe object and stored in the tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8481510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviewText  overall\n",
      "0     They look good and stick good! I just don't li...      4.0\n",
      "1     These stickers work like the review says they ...      5.0\n",
      "2     These are awesome and make my phone look so st...      5.0\n",
      "3     Item arrived in great time and was in perfect ...      4.0\n",
      "4     awesome! stays on, and looks great. can be use...      5.0\n",
      "...                                                 ...      ...\n",
      "9995  WHAT COMES IN THE BOXCaseMicro USB CableInstru...      4.0\n",
      "9996  No wonder the price was so low, this battery p...      1.0\n",
      "9997  I bought this almost 2 years ago honestly, and...      5.0\n",
      "9998  I bought this originally for the outrageous pr...      1.0\n",
      "9999  Good style is essential to any Apple design. I...      4.0\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Creating a subset of the DataFrame 'df' by copying the first 10,000 rows and assigns it to 'df_subset'. \n",
    "df_subset = df.head(10000).copy()\n",
    "print(df_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2261f301",
   "metadata": {},
   "source": [
    "#### This creates new dataframe object with top 10000 rows from the orginal dataset. The function .copy() is used to create deep copy of the subset dataframe . It ensures that any modifications done to the subset will not affect the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e1e27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy==3.5.2\n",
      "  Downloading spacy-3.5.2-cp39-cp39-win_amd64.whl (12.2 MB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from spacy==3.5.2) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda\\lib\\site-packages (from spacy==3.5.2) (4.62.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from spacy==3.5.2) (1.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda\\lib\\site-packages (from spacy==3.5.2) (58.0.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from spacy==3.5.2) (2.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda\\lib\\site-packages (from spacy==3.5.2) (21.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from spacy==3.5.2) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda\\lib\\site-packages (from spacy==3.5.2) (2.11.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from spacy==3.5.2) (1.0.4)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from spacy==3.5.2) (0.10.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from spacy==3.5.2) (1.1.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda\\lib\\site-packages (from spacy==3.5.2) (2.26.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from spacy==3.5.2) (1.10.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from spacy==3.5.2) (2.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from spacy==3.5.2) (2.4.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda\\lib\\site-packages (from spacy==3.5.2) (1.20.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from spacy==3.5.2) (3.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from spacy==3.5.2) (0.7.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from spacy==3.5.2) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from spacy==3.5.2) (8.1.10)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda\\lib\\site-packages (from packaging>=20.0->spacy==3.5.2) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy==3.5.2) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.2) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.2) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.2) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.2) (2.0.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.8->spacy==3.5.2) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.8->spacy==3.5.2) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\sniggdha\\appdata\\roaming\\python\\python39\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy==3.5.2) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy==3.5.2) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda\\lib\\site-packages (from jinja2->spacy==3.5.2) (1.1.1)\n",
      "Installing collected packages: spacy\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.5.3\n",
      "    Uninstalling spacy-3.5.3:\n",
      "      Successfully uninstalled spacy-3.5.3\n",
      "Successfully installed spacy-3.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Installing the specific version 3.5.2 of the 'spacy' library using pip.\n",
    "pip install spacy==3.5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c5d1a",
   "metadata": {},
   "source": [
    "#### pip install spacy==3.5.2 installing spacy version 3.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ab61b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy #Importing Library\n",
    "nlp = spacy.load('en_core_web_sm') #loading the 'en_core_web_sm' model from the 'spacy' library into the 'nlp' variable for English language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de3f7f6",
   "metadata": {},
   "source": [
    "#### Importing a python library spacy, which is a natural language processing library in Python. \n",
    "#### nlp = spacy.load('en_core_web_sm'):- This loads small sized English Language Model provided by spacy that includes vocbulary,syntax and NER for processing English Text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7a20e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterating over each row in the DataFrame 'df_subset', processes the 'reviewText' column using the 'nlp' model from spaCy, converting the text to lowercase, and assigning the lowercase version back to the 'reviewText' column in 'df_subset'.\n",
    "\n",
    "for index, row in df_subset.iterrows():\n",
    "    doc = nlp(row['reviewText'])\n",
    "    lowercase_text = ' '.join(token.text.lower() for token in doc)\n",
    "    df_subset.at[index, 'reviewText'] = lowercase_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336a125f",
   "metadata": {},
   "source": [
    "#### The above code is created to lowercase each reviewText in the dataframe.\n",
    "#### To do so we are iterrating each row and then applying Spacy's NLP pipleline to each reviewText. This NLP applied then creates a docc object which contains analyzed text.\n",
    "#### lowercase_text = ' '.join(token.text.lower() for token in doc): This line iterates over each text in the doc, converts the token text to lowercase using the lower() method, and joins them back into a string with space as the separator. This results in the lowercased text.\n",
    "#### df_subset.at[index, 'reviewText'] = lowercase_text: This line replaces the  value of 'reviewText' column of the current row in the df_subset DataFrame with the lowercase text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59bd1abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviewText  overall\n",
      "0     they look good and stick good ! i just do n't ...      4.0\n",
      "1     these stickers work like the review says they ...      5.0\n",
      "2     these are awesome and make my phone look so st...      5.0\n",
      "3     item arrived in great time and was in perfect ...      4.0\n",
      "4     awesome ! stays on , and looks great . can be ...      5.0\n",
      "...                                                 ...      ...\n",
      "9995  what comes in the boxcasemicro usb cableinstru...      4.0\n",
      "9996  no wonder the price was so low , this battery ...      1.0\n",
      "9997  i bought this almost 2 years ago honestly , an...      5.0\n",
      "9998  i bought this originally for the outrageous pr...      1.0\n",
      "9999  good style is essential to any apple design . ...      4.0\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ee46270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function named 'without_punctuation' that takes a text input, processing it using the 'nlp' model from spaCy, removing punctuation tokens from the processed text, and returning the resulting text without punctuation.\n",
    "\n",
    "def without_punctuation(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc if not token.is_punct]\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4585cf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviewText  overall\n",
      "0     they look good and stick good i just do n't li...      4.0\n",
      "1     these stickers work like the review says they ...      5.0\n",
      "2     these are awesome and make my phone look so st...      5.0\n",
      "3     item arrived in great time and was in perfect ...      4.0\n",
      "4     awesome stays on and looks great can be used o...      5.0\n",
      "...                                                 ...      ...\n",
      "9995  what comes in the boxcasemicro usb cableinstru...      4.0\n",
      "9996  no wonder the price was so low this battery pa...      1.0\n",
      "9997  i bought this almost 2 years ago honestly and ...      5.0\n",
      "9998  i bought this originally for the outrageous pr...      1.0\n",
      "9999  good style is essential to any apple design i ...      4.0\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_subset['reviewText'] = df_subset['reviewText'].apply(without_punctuation)\n",
    "print(df_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d408350d",
   "metadata": {},
   "source": [
    "#### This is another pre-processing steps wherein we have defined a function to remove punctuations from the review text. In the function we have used Spacy English Model and added sentencizer to do sentence tokenisation.\n",
    "#### The next step in the defined function checks for each character in the text variable whether it is a charcter or not using punctuation tokens. If it is a character  then it filters out. So the output of the defined function is a text without punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec68ae4b",
   "metadata": {},
   "source": [
    "#### In the line 11, we are applying the defined function for each row in the df_subset dataframe to remove punctations from each and every reviewsText. Hence, the resulted output has no punctuation in the reviewText ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83b960f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math #Importing Library\n",
    "\n",
    "word_doc_freq = df_subset['reviewText'].apply(lambda x: set(x.split())).explode().value_counts().to_dict()\n",
    "\n",
    "\n",
    "num_docs = len(df_subset)\n",
    "idf_scores = {}\n",
    "for word, freq in word_doc_freq.items():\n",
    "    idf_scores[word] = math.log(num_docs / freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf361df",
   "metadata": {},
   "source": [
    "#### This imports the math module which provides mathematical functions and library.\n",
    "#### word_doc_freq: This line calculates the document frequency for each word in the reviewText column. \n",
    "#### df_subset['reviewText'].apply(lambda x: set(x.split())): This applies a lambda function to each review text in the reviewText column. The lambda function splits each review text into individual words and converts them into a set to remove duplicates.\n",
    "#### .explode(): This function converts each set of words into separate rows, resulting in a new DataFrame where each word appears in a separate row.\n",
    "#### .value_counts(): This counts the frequency of each word in the DataFrame, giving us the document frequency for each word.\n",
    "#### .to_dict(): This converts the resulting pandas Series into a dictionary, where the keys are words and the values are their document frequencies.\n",
    "#### num_docs:-This calculates the total number of reviews in the DataFrame.\n",
    "#### idf_scores[word] = math.log(num_docs / freq): This calculates the IDF score for each word using the formula iterating in a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27682e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javoedge: 9.210340371976184\n",
      "version:----------------------------------if: 9.210340371976184\n",
      "betterspend: 9.210340371976184\n",
      "jostled: 9.210340371976184\n",
      "3gone: 9.210340371976184\n",
      "clocked: 9.210340371976184\n",
      "commensurate: 9.210340371976184\n",
      "phone.)all: 9.210340371976184\n",
      "forthcoming: 9.210340371976184\n",
      "twp: 9.210340371976184\n",
      "dissemble: 9.210340371976184\n",
      "crackled: 9.210340371976184\n",
      "is.-: 9.210340371976184\n",
      "yorkcity: 9.210340371976184\n",
      "removability: 9.210340371976184\n",
      "evaluating: 9.210340371976184\n",
      "disgust: 9.210340371976184\n",
      "iwill: 9.210340371976184\n",
      "perfectly3: 9.210340371976184\n",
      "icarpus: 9.210340371976184\n"
     ]
    }
   ],
   "source": [
    "idf_scores\n",
    "sort_idf_scores = sorted(idf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get the top 20 words and their IDF scores\n",
    "top_20_words = sort_idf_scores[:20]\n",
    "\n",
    "# Get the bottom 20 words and their IDF scores\n",
    "bottom_20_words = sort_idf_scores[-20:][::-1]\n",
    "\n",
    "for word, score in top_20_words:\n",
    "    print(f\"{word}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d055a",
   "metadata": {},
   "source": [
    "#### sort_idf_scores:- This sorts the words in idf_scores in descending order based on their tfidf scores\n",
    "#### top_20_words:- Selecting top 20 tfidf scored words\n",
    "#### bottom_20_words:- Selecting bottom 20 tfidf scored words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c550262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 0.1694843079924628\n",
      "i: 0.22652425947368723\n",
      "and: 0.23294139379432077\n",
      "it: 0.2410529718577776\n",
      "a: 0.29988961555952587\n",
      "to: 0.33128570993391293\n",
      "this: 0.40137349020491087\n",
      "is: 0.4714446670421397\n",
      "for: 0.5013704649952355\n",
      "my: 0.5480084148937067\n",
      "of: 0.6717771548237528\n",
      "in: 0.7172349760890353\n",
      "with: 0.7298111649315369\n",
      "that: 0.7410777143174954\n",
      "but: 0.7914217498282858\n",
      "on: 0.8047493571412477\n",
      "have: 0.8340197394413609\n",
      "not: 0.8528465593176202\n",
      "phone: 0.9213032736976995\n",
      "you: 0.9926319651308776\n"
     ]
    }
   ],
   "source": [
    "for word, score in bottom_20_words:\n",
    "    print(f\"{word}: {score}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fdd52f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
